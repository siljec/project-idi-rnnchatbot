import os, re
from create_vocabulary import read_vocabulary_from_file, encode_sentence, create_vocabulary, find_dictionary
from spell_error_fix import replace_mispelled_words_in_file

def preprocess_training_file(path, x_train_path, y_train_path):
	
	user1_first_line = True

	x_train = []
	y_train = []

	sentence_holder = ""

	with open(path) as fileobject:
		for line in fileobject:
			data = line.split("\t")
			current_user = data[1]
			text = data[3].strip().lower()
			text = re.sub(' +', ' ', text) # Will remove multiple spaces
			text = re.sub('(?<=[a-z])([!?,.])', r' \1', text) # Add space before special characters [!?,.]

			if user1_first_line:
				init_user = current_user
				previous_user = current_user
				user1_first_line = False
				sentence_holder = "_GO "

			if current_user == previous_user: 		# The user is still talking
				sentence_holder += text + " _EOS "
			else: 									# A new user responds
				if ('_EOS' in sentence_holder):
					sentence_holder += "_EOT \n"
				else:
					sentence_holder += " _EOT \n"
				if current_user == init_user: 		# Init user talks (should add previus sentence to y_train)
					y_train.append(sentence_holder)
				else:
					x_train.append(sentence_holder)
				sentence_holder = '_GO ' + text + ' _EOS '

			previous_user = current_user


	if current_user != init_user:
		y_train.append(sentence_holder + "_EOT \n")

	x_train_file = open(x_train_path, 'a')
	y_train_file = open(y_train_path, 'a')

	for i in range(len(y_train)):
		x_train_file.write(x_train[i])
		y_train_file.write(y_train[i])

	x_train_file.close()
	y_train_file.close()

def file_len(fname):
    with open(fname) as f:
        for i, l in enumerate(f):
            pass
    return i + 1

def create_final_files(source_path, train_path, vocabulary_path, dev_path, dev_size_fraction):
	vocabulary, _ = read_vocabulary_from_file(vocabulary_path)
	train_final = open(train_path, 'w')
	dev_final = open(dev_path, 'w')
	num_lines = file_len(source_path)
	train_size = num_lines*(1-dev_size_fraction)
	line_counter = 0
	with open(source_path) as fileobject:
		for line in fileobject:
			if line_counter < train_size:
				train_final.write(encode_sentence(line.split(" "), vocabulary) + '\n')
			else:
				dev_final.write(encode_sentence(line.split(" "), vocabulary) + '\n')
			line_counter += 1.0
	train_final.close()
	dev_final.close()

def read_every_data_file_and_create_initial_files(initial_x_file_path, initial_y_file_path, number_of_folders, number_of_files):
	number_of_files_read = 0 # Can remove, but nice for the report best regards siljus christus
	for folder in os.listdir("../../ubuntu-ranking-dataset-creator/src/dialogs"):
		if(number_of_folders < 0):
			break
		number_of_folders -= 1
		if folder != ".DS_Store":
			folder_path = "../../ubuntu-ranking-dataset-creator/src/dialogs/" + folder
			for filename in os.listdir(folder_path):
				if(number_of_files == 0):
					break
				number_of_files -= 1
				number_of_files_read += 1
				file_path = folder_path + "/" + filename
				preprocess_training_file(file_path, initial_x_file_path, initial_y_file_path)


####################################################
misspelled_words_path = './misspellings.txt' # Is not generated by the code. Don't delete!
vocabulary_size = 1000
vocabulary_path = './vocabulary.txt'
x_train_initial_path = './x_train_init.txt'
y_train_initial_path = './y_train_init.txt'
x_train_spell_check_path = './x_train_spell_check.txt'
y_train_spell_check_path = './y_train_spell_check.txt'
x_train_final_path = './x_train.txt'
y_train_final_path = './y_train.txt'
x_dev_path = './x_dev.txt'
y_dev_path = './y_dev.txt'

def generate_all_files():
	# Remove all files if exists
	all_files = [x_train_initial_path, y_train_initial_path, x_train_spell_check_path, y_train_spell_check_path, x_train_final_path, y_train_final_path, vocabulary_path, x_dev_path, y_dev_path]
	for filename in all_files:
		try:
			os.remove(filename)
		except OSError:
			print 'File not found: ', filename

	print 'Reading all the files and create initial files...'
	read_every_data_file_and_create_initial_files(x_train_initial_path, y_train_initial_path, 1, 11)

	print 'Spellchecker for the initial files, create new spell checked files...' 
	replace_mispelled_words_in_file(x_train_initial_path, x_train_spell_check_path, misspelled_words_path)
	replace_mispelled_words_in_file(y_train_initial_path, y_train_spell_check_path, misspelled_words_path)

	print 'Creating vocabulary...'
	sorted_dict = find_dictionary(x_train_spell_check_path, y_train_spell_check_path)
	create_vocabulary(sorted_dict, vocabulary_path, vocabulary_size)

	print 'Creating final files...'
	create_final_files(x_train_spell_check_path, x_train_final_path, vocabulary_path, x_dev_path, dev_size_fraction=0.1)
	create_final_files(y_train_spell_check_path, y_train_final_path, vocabulary_path, y_dev_path, dev_size_fraction=0.1)



generate_all_files()

